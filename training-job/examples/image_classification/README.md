## Training image classification model using FSDP

In this example we train an image classification model using Hugging Face Trainer and FSDP. The code has been adapted from - [repository](https://github.com/huggingface/transformers/blob/main/examples/pytorch/image-classification/run_image_classification.py)

More information on fsdp - [here](https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/)

## Parameters for the script

1. dataset_name - name of the hugging face dataset. Any dataset from [hugging face dataset repository](https://huggingface.co/datasets) can be used
2. output_dir - Directory to save the results and checkpoints
3. do_train - Include training
4. do_eval - Include testing
5. learning_rate - leanring rate of the model
6. num_train_epochs - Total number of epochs to train
7. per_device_train_batch_size - Training batch size
8. per_device_eval_batch_size - Testing batch size
9. load_best_model_at_end - To save the final model
10. seed - Random Seed

Distributed training (torch elastic) parameters

1. nproc_per_node - number of gpus to use

FSDP related parameters

1. fsdp - fsdp wrap type 
2. fsdp_min_num_params - minimum number of parameters for fsdp

## Running the code

For training the model in GPU

```
python image_classification.py \
      --dataset_name beans \
      --output_dir ./beans_outputs/ \
      --remove_unused_columns False \
      --do_train \
      --do_eval \
      --learning_rate 2e-5 \
      --num_train_epochs 5 \
      --per_device_train_batch_size 8 \
      --per_device_eval_batch_size 8 \
      --logging_strategy steps \
      --logging_steps 10 \
      --evaluation_strategy epoch \
      --save_strategy epoch \
      --load_best_model_at_end True \
      --save_total_limit 3 \
      --seed 1337
```

To train the model in Distributed mode using fsdp

```
torchrun --nproc_per_node=4 image_classification.py \
      --dataset_name beans \
      --output_dir ./beans_outputs/ \
      --remove_unused_columns False \
      --do_train \
      --do_eval \
      --learning_rate 2e-5 \
      --num_train_epochs 5 \
      --per_device_train_batch_size 8 \
      --per_device_eval_batch_size 8 \
      --logging_strategy steps \
      --logging_steps 10 \
      --evaluation_strategy epoch \
      --save_strategy epoch \
      --load_best_model_at_end True \
      --save_total_limit 3 \
      --seed 1337 \
      --fsdp "full_shard auto_wrap" \
      --fsdp_min_num_params 20000
```

Note: To train the model using fsdp , `transformers` package should be compiled from source

## Model 

The script finetunes Vision Transformers model - `google/vit-base-patch16-224-in21k` which is available in hugging face model repostiory.

More information on the model - [here](https://huggingface.co/google/vit-base-patch16-224-in21k)

To finetune a different model - pick the model name from [here](https://huggingface.co/models)

And change the model_name argument accordingly


## Sample output

At the end of the traning following output files are generated in the output folder

1. runs - Tensorboard trace
2.  all_results.json - All the results together

```
{
    "epoch": 5.0,
    "eval_accuracy": 0.994,
    "eval_loss": 0.03872646391391754,
    "eval_runtime": 18.2409,
    "eval_samples_per_second": 411.164,
    "eval_steps_per_second": 12.883,
    "train_loss": 0.3321523506180338,
    "train_runtime": 1525.2978,
    "train_samples_per_second": 139.317,
    "train_steps_per_second": 4.357
}
```

3. config.json - Config used for training

```
{
  "_name_or_path": "google/vit-base-patch16-224-in21k",
  "architectures": [
    "ViTForImageClassification"
  ],
  "attention_probs_dropout_prob": 0.0,
  "encoder_stride": 16,
  "finetuning_task": "image-classification",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "id2label": {
    "0": "airplane",
    "1": "automobile",
    "2": "bird",
    "3": "cat",
    "4": "deer",
    "5": "dog",
    "6": "frog",
    "7": "horse",
    "8": "ship",
    "9": "truck"
  },
  "image_size": 224,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "airplane": "0",
    "automobile": "1",
    "bird": "2",
    "cat": "3",
    "deer": "4",
    "dog": "5",
    "frog": "6",
    "horse": "7",
    "ship": "8",
    "truck": "9"
  },
  "layer_norm_eps": 1e-12,
  "model_type": "vit",
  "num_attention_heads": 12,
  "num_channels": 3,
  "num_hidden_layers": 12,
  "patch_size": 16,
  "problem_type": "single_label_classification",
  "qkv_bias": true,
  "torch_dtype": "float32",
  "transformers_version": "4.21.0.dev0"
}
```

4. pytorch-model.bin - the model output 

5. README.md - Autogenerated readme file with training results.